{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd0220-02ff-4e11-bb1f-60a1633286cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import cached_conv as cc\n",
    "import gin\n",
    "import torch\n",
    "\n",
    "from msprior.attention import Prior\n",
    "from msprior.dataset import SequenceDataset\n",
    "\n",
    "cc.use_cached_conv(True)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "run = \"runs/encoder_decoder_continuous/\"\n",
    "db_path = \"/data/antoine/rave2vec_jax/preprocessed\"\n",
    "\n",
    "config = pathlib.Path(run).rglob(\"*.gin\")\n",
    "config = str(list(config)[0])\n",
    "\n",
    "gin.clear_config()\n",
    "gin.parse_config_file(config)\n",
    "\n",
    "model = Prior().eval()\n",
    "\n",
    "try:\n",
    "    ckpt = pathlib.Path(run).rglob(\"*best*.ckpt\")\n",
    "    ckpt = str(list(ckpt)[0])\n",
    "    print(f\"loading {ckpt}\")\n",
    "    ckpt = torch.load(ckpt, map_location=\"cpu\")[\"state_dict\"]\n",
    "    model.load_state_dict(ckpt)\n",
    "    print(\"checkpoint restored\")\n",
    "except:\n",
    "    print(\"could not restore checkpoint\")\n",
    "\n",
    "gin.parse_config(\"SEQ_LEN=512\")\n",
    "dataset = SequenceDataset(db_path)\n",
    "\n",
    "rave = pathlib.Path(db_path).glob(\"*.ts\")\n",
    "rave = str(list(rave)[0])\n",
    "rave = torch.jit.load(rave).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acae81a-03c9-4f6a-bf0a-6dcd6f66847c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "\n",
    "data_idx = 18282\n",
    "batch = dataset[data_idx]\n",
    "z = torch.from_numpy(batch[\"decoder_inputs\"].T[None])\n",
    "\n",
    "audio = rave.decode(z)\n",
    "\n",
    "display(Audio(audio.reshape(-1).numpy(), rate=rave.sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee6aa3d-0910-407e-bc73-96da0fa70559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "# RESET\n",
    "for n, m in model.named_modules():\n",
    "    if n[-9:] != \"attention\":\n",
    "        continue\n",
    "    m.reset()\n",
    "\n",
    "samples = torch.from_numpy(batch[\"decoder_inputs\"][None, :256])\n",
    "try:\n",
    "    semantic = torch.from_numpy(batch[\"encoder_inputs\"][None, :64])\n",
    "    semantic_next = torch.from_numpy(batch[\"encoder_inputs\"][None, 64:])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if \"only\" in run:\n",
    "    semantic = None\n",
    "\n",
    "temperature = .85\n",
    "\n",
    "current_sample = model.sample(samples, semantic, temperature)[0][:, -1:]\n",
    "samples = torch.cat([samples, current_sample], 1)\n",
    "\n",
    "for t in trange(255):\n",
    "    s_index = t // 4\n",
    "    if semantic is not None:\n",
    "        current_semantic = semantic_next[:, s_index:s_index + 1]\n",
    "    else:\n",
    "        current_semantic = None\n",
    "\n",
    "    current_sample = model.sample(current_sample, current_semantic,\n",
    "                                  temperature)[0]\n",
    "    samples = torch.cat([samples, current_sample], 1)\n",
    "\n",
    "audio_gen = rave.decode(samples.permute(0, 2, 1)).reshape(-1).numpy()\n",
    "display(Audio(audio_gen, rate=rave.sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf0af13-c547-48ce-a345-900e10ead3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as li\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_melspec(x):\n",
    "    x = np.asarray(x).reshape(-1)\n",
    "    x = li.feature.melspectrogram(y=x, sr=rave.sr)\n",
    "    x = np.log1p(abs(x))\n",
    "    return x\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 8))\n",
    "\n",
    "axes[0].matshow(get_melspec(audio), aspect=\"auto\", origin=\"lower\")\n",
    "axes[1].matshow(get_melspec(audio_gen), aspect=\"auto\", origin=\"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653f27a-e34c-4297-beb2-d02c0407c000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_np = np.asarray(audio).reshape(-1)\n",
    "\n",
    "audio_stack = np.stack([audio_np, audio_gen], 0)\n",
    "\n",
    "display(Audio(audio_stack, rate=rave.sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383130aa-763c-47a1-8e26-21b78130f620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from udls import AudioExample\n",
    "\n",
    "with dataset.env.begin() as txn:\n",
    "    ae = AudioExample(txn.get(dataset.keys[data_idx]))\n",
    "ae = ae.as_dict()\n",
    "\n",
    "with open(\"/data/antoine/rave2vec_jax/preprocessed/kmeans\", \"rb\") as kmeans:\n",
    "    kmeans = pickle.load(kmeans)\n",
    "\n",
    "clusters = kmeans.cluster_centers_\n",
    "\n",
    "tokens = ae[\"semantic_indices\"]\n",
    "features = ae[\"semantic_features\"]\n",
    "tokenized_features = np.take(clusters, tokens, 0)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 8))\n",
    "axes[0].matshow(features, aspect=\"auto\")\n",
    "axes[1].matshow(tokenized_features, aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e5285-9b19-4c5c-8bff-da1f9dbd0881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.matshow(abs(features.T - tokenized_features.T), origin=\"lower\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6186809f-90d2-4eb3-8b83-d99fd20f0c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
